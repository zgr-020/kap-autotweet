import os, re, json, time
from pathlib import Path
from playwright.sync_api import sync_playwright, TimeoutError as PWTimeout
import tweepy

# ==== X (Twitter) eriÅŸimi ====
API_KEY = os.getenv("API_KEY")
API_KEY_SECRET = os.getenv("API_KEY_SECRET")
ACCESS_TOKEN = os.getenv("ACCESS_TOKEN")
ACCESS_TOKEN_SECRET = os.getenv("ACCESS_TOKEN_SECRET")

client = tweepy.Client(
    consumer_key=API_KEY,
    consumer_secret=API_KEY_SECRET,
    access_token=ACCESS_TOKEN,
    access_token_secret=ACCESS_TOKEN_SECRET
)

# ==== KalÄ±cÄ± durum (aynÄ± KAP id'sini ikinci kez atma) ====
STATE_FILE = Path("state.json")
posted = set(json.loads(STATE_FILE.read_text())) if STATE_FILE.exists() else set()
def save_state():
    STATE_FILE.write_text(json.dumps(sorted(list(posted)), ensure_ascii=False))

# ==== Metin yardÄ±mcÄ±larÄ± ====
STOP_PHRASES = [
    r"iÅŸbu aÃ§Ä±klama.*?amaÃ§la", r"bu aÃ§Ä±klama.*?kapsamÄ±nda", r"kamunun bilgisine arz olunur",
    r"saygÄ±larÄ±mÄ±zla", r"yatÄ±rÄ±mcÄ±larÄ±mÄ±zÄ±n bilgisine", r"Ã¶zel durum aÃ§Ä±klamasÄ±",
    r"yatÄ±rÄ±m tavsiyesi", r"iÅŸbu .*? kapsamÄ±ndadÄ±r"
]
def clean_text(t: str) -> str:
    t = re.sub(r"\s+", " ", (t or "")).strip()
    for p in STOP_PHRASES:
        t = re.sub(p, "", t, flags=re.I)
    return t.strip(" -â€“â€”:.")

def summarize(text: str, limit: int) -> str:
    """KÄ±sa ve doÄŸal bir Ã¶zet: ilk 1â€“2 anlamlÄ± cÃ¼mleyi al, limite yaklaÅŸÄ±nca dur."""
    text = clean_text(text)
    sents = re.split(r"(?<=[.!?])\s+", text)
    out = ""
    for s in sents:
        if not s: 
            continue
        cand = (out + " " + s).strip()
        if len(cand) > limit:
            break
        out = cand
        if len(out) >= limit * 0.7:
            break
    return out or text[:limit]

def is_pnl_news(title: str, body: str) -> bool:
    blob = (title or "") + " " + (body or "")
    return bool(re.search(r"\b(kÃ¢r|kar|zarar|net dÃ¶nem kar|dÃ¶nem karÄ±|zararÄ±|finansal sonuÃ§)\b", blob.lower()))

def format_tweet(code: str, title: str, body: str) -> str:
    head_emoji = "ğŸ’°" if is_pnl_news(title, body) else "ğŸ“°"
    head = f"{head_emoji} #{code} | "
    return (head + summarize(body or title, 279 - len(head)))[:279]

# ==== Detay sayfasÄ± okuyucular ====
def extract_kv_table(page) -> dict:
    """th/td tablosunu sÃ¶zlÃ¼ÄŸe Ã§evirir (alan adÄ± -> deÄŸer)."""
    kv = {}
    rows = page.locator("table tr")
    n = rows.count()
    for i in range(n):
        th = rows.nth(i).locator("th")
        td = rows.nth(i).locator("td")
        if th.count() > 0 and td.count() > 0:
            key = th.first.inner_text().strip().lower()
            val = td.first.inner_text().strip()
            if key and val:
                kv[key] = val
    return kv

def build_finance_summary(kv: dict) -> str:
    """Tutar, vade, faiz, ISIN, aracÄ± vb. alanlardan kÄ±sa Ã¶zet Ã¼retir."""
    # isim varyasyonlarÄ±
    tutar = kv.get("tutar") or kv.get("gerÃ§ekleÅŸtirilen nominal tutar") or kv.get("satÄ±ÅŸa konu nominal tutar") or kv.get("ihraÃ§ tavanÄ± tutarÄ±")
    vade  = kv.get("vade tarihi") or kv.get("vade") or kv.get("vade (gÃ¼n)")
    faiz  = kv.get("faiz oranÄ± - yÄ±llÄ±k basit (%)") or kv.get("faiz oranÄ± (%)") or kv.get("faiz oranÄ±") or kv.get("kupon faizi")
    isin  = kv.get("isin kodu") or kv.get("isin kod") or kv.get("isin")
    arac  = kv.get("aracÄ±lÄ±k hizmeti alÄ±nan yatÄ±rÄ±m kuruluÅŸu") or kv.get("aracÄ± kurum") or kv.get("aracÄ± kurum/kuruluÅŸ")
    tip   = kv.get("bildirim konusu") or kv.get("konu") or kv.get("iÅŸlem tÃ¼rÃ¼")

    parts = []
    if tip:   parts.append(tip)
    if tutar: parts.append(tutar)
    if vade:  parts.append(f"vade {vade}")
    if faiz:  parts.append(f"faiz %{faiz}")
    if isin:  parts.append(f"ISIN {isin}")
    if arac:  parts.append(f"aracÄ±: {arac}")
    return ", ".join([p for p in parts if p])

def extract_company_note(page) -> str:
    """
    SayfanÄ±n altÄ±ndaki 'Ek AÃ§Ä±klamalar' / 'AÃ§Ä±klamalar' vb. serbest metni dÃ¶ndÃ¼rÃ¼r.
    Yoksa boÅŸ string.
    """
    # 1) 'Ek AÃ§Ä±klamalar' bir th/td satÄ±rÄ± olarak gelebilir
    try:
        el = page.locator("xpath=//th[contains(.,'Ek AÃ§Ä±klamalar')]/following-sibling::td")
        if el.count() > 0:
            txt = el.first.inner_text().strip()
            if len(txt) > 20:
                return txt
    except Exception:
        pass
    # 2) En alttaki paragraflar
    try:
        p_tags = page.locator("article p, .content p, p")
        n = p_tags.count()
        if n > 0:
            # sondan birkaÃ§ paragrafÄ± birleÅŸtir (genelde not en altta)
            tail = " ".join(p_tags.nth(i).inner_text() for i in range(max(0, n-3), n))
            tail = clean_text(tail)
            # Ã§ok uzunsa kÄ±salacak zaten; yeter ki en az 20 karakter olsun
            if len(tail) > 20:
                return tail
    except Exception:
        pass
    return ""

# ==== Liste sayfasÄ±ndan satÄ±r Ã§ekme ====
def fetch_list_items(page):
    """
    Bildirim listesinde her satÄ±r iÃ§in:
    - code (hisse kodu)
    - title (Konu)
    - url (Detay linki)
    - id  (linkten Ã§Ä±karÄ±lan numerik id)
    dÃ¶ner.
    """
    items = []
    rows = page.locator("table tbody tr")
    n = rows.count()
    for i in range(n):
        row = rows.nth(i)
        tds = row.locator("td")
        if tds.count() < 5:
            continue
        code  = tds.nth(1).inner_text().strip()
        title = tds.nth(4).inner_text().strip()

        # Detay linki; ikon veya metin olabilir
        link = ""
        lc = row.locator('a[href*="/tr/Bildirim/"], a[href*="/tr/bildirim/"]')
        if lc.count() > 0:
            link = lc.first.get_attribute("href")
        if not link:
            a = row.locator("a")
            if a.count() > 0:
                link = a.first.get_attribute("href")

        if not (code and title and link):
            continue
        m = re.search(r"(\d{6,})", link)
        kap_id = m.group(1) if m else link
        items.append({"id": kap_id, "code": code, "title": title, "url": link})
    return items

# ==== Ana akÄ±ÅŸ ====
def main():
    print(">> start")
    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=True,
            args=["--no-sandbox", "--disable-gpu", "--disable-dev-shm-usage"]
        )
        context = browser.new_context(
            user_agent=("Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
                        "(KHTML, like Gecko) Chrome/120.0 Safari/537.36"),
            locale="tr-TR",
            timezone_id="Europe/Istanbul"
        )
        page = context.new_page()
        page.set_default_timeout(20000)

        # Liste sayfasÄ±nÄ± aÃ§
        try:
            page.goto("https://www.kap.org.tr/tr/bildirim-sorgu", wait_until="load")
            # Ã‡erez/KVKK bandÄ± varsa kapat
            try:
                btn = page.locator("button:has-text('Kabul Et'), button:has-text('KABUL ET')")
                if btn.count() > 0:
                    btn.first.click()
                    print(">> cookie accepted")
            except Exception:
                pass
            page.wait_for_selector("table tbody tr", timeout=15000)
        except PWTimeout:
            print("!! tablo gelmedi (timeout)")
            browser.close()
            return

        items = fetch_list_items(page)
        print(f">> parsed items: {len(items)}")

        # Sadece yeni olanlar
        new_items = [it for it in items if it["id"] not in posted]
        print(f">> new items: {len(new_items)} (posted: {len(posted)})")

        # Kronolojik sÄ±rayla gÃ¶nder (eskiden yeniye)
        new_items.reverse()

        for it in new_items:
            # Detay sayfasÄ±nÄ± aÃ§
            page.goto(it["url"], wait_until="load")
            page.wait_for_timeout(1200)

            # 1) KV tablo â†’ finansal Ã¶zet
            kv = extract_kv_table(page)
            fin_sum = build_finance_summary(kv)

            # 2) Ã–zet Bilgi (varsa)
            ozet = ""
            try:
                el = page.locator("xpath=//th[contains(.,'Ã–zet Bilgi')]/following-sibling::td")
                if el.count() > 0:
                    ozet = el.first.inner_text().strip()
            except Exception:
                pass

            # 3) Åirketin serbest "aÃ§Ä±klama notu" (en altta)
            note = extract_company_note(page)

            # Ã–ncelik: aÃ§Ä±klama notu > finansal Ã¶zet > Ã¶zet bilgi > baÅŸlÄ±k
            body = note or fin_sum or ozet or it["title"]

            tweet = format_tweet(it["code"], it["title"], body)
            print(">> TWEET:", tweet)

            try:
                client.create_tweet(text=tweet)
                posted.add(it["id"])
                save_state()
                print(">> tweet sent âœ“")
                time.sleep(1.5)  # nazikÃ§e
            except Exception as e:
                print("!! tweet error:", e)

        browser.close()
        print(">> done")

if __name__ == "__main__":
    main()
